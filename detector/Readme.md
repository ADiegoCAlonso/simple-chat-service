# LLM Model detector

## How to Run This

1.  **Ensure your Docker container is running** (from the previous step):
    ```bash
    docker run -p 8000:80 simple-chat-bot
    ```

2.  **Install the script dependencies**:
    ```bash
    pip install -r detector_requirements.txt
    ```

3.  **Run the detector**:
    ```bash
    python llm_detector.py

